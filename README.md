# Resources_papers_tools_whitepapers_
ML privacy and security papers, tools and articles/blogs/videos

This is a collection of research papers, tools, articles etc. that were part of literature survey to learn about ML privacy and security.




Adversarial ML:

[Intriguing properties of NN](https://arxiv.org/abs/1312.6199)

[STATISTICAL SPAM FILTER FOR EMAIL](https://ix.cs.uoregon.edu/~lowd/ceas05lowd.pdf)

[adversarial classification](https://homes.cs.washington.edu/~pedrod/papers/kdd04.pdf)

[Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples](https://arxiv.org/abs/1605.07277)

[Practical Black-Box Attacks against Machine Learning](https://arxiv.org/abs/1602.02697)

[Adversarial examples of realworld](https://arxiv.org/abs/1607.02533)





PRIVACY ATTACKS:


[Robust De-anonymization of Large Sparse Datasets](https://www.cs.utexas.edu/~shmat/shmat_oak08netflix.pdf)


[Unique in the Crowd: The privacy bounds of human mobility](https://www.nature.com/articles/srep01376)



[Stealing Machine Learning Models via Prediction APIs](https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_tramer.pdf)



[Membership Inference Attacks against Machine Learning Models](https://arxiv.org/abs/1610.05820)



[The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks](https://arxiv.org/abs/1802.08232)



[Overlearning Reveals Sensitive Attributes](https://arxiv.org/abs/1905.11742)




DIFFERENTIAL PRIVACY:

[RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42852.pdf)


[Quantifying Differential Privacy in Continuous Data Release under Temporal Correlations](https://arxiv.org/pdf/1711.11436.pdf)


[Extremal Mechanisms for Local Differential Privacy](https://proceedings.neurips.cc/paper_files/paper/2014/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)


[Differentially Private Aggregation of Distributed Time-Series with Transformation and Encryption](https://www.microsoft.com/en-us/research/wp-content/uploads/2009/11/paper.pdf)


[The Algorithmic Foundations of Differential Privacy](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf)


[The Composition Theorem for Differential Privacy](https://arxiv.org/abs/1311.0776)


[privbayes](http://dimacs.rutgers.edu/~graham/pubs/papers/PrivBayes.pdf)




Federated learning


[Communication-Efficient Learning of Deep Networks from Decentralized Data](http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf)


[Advances and Open Problems in Federated Learning](https://arxiv.org/pdf/1912.04977.pdf)



[LEARNING DIFFERENTIALLY PRIVATE RECURRENT LANGUAGE MODELS](https://arxiv.org/pdf/1710.06963.pdf)



[Differentially Private Federated Learning: A Client Level Perspective](https://arxiv.org/pdf/1712.07557.pdf)


[Think Locally, Act Globally:
Federated Learning with Local and Global Representations](https://arxiv.org/pdf/2001.01523v1.pdf)





TOOLS:


[Privacy-Raven](https://github.com/trailofbits/PrivacyRaven)


[privacy_meter](https://github.com/privacytrustlab/ml_privacy_meter)


[cyphercat](https://github.com/Lab41/cyphercat)



[cleverhans](http://www.cleverhans.io)


[adversarial_robustness](https://github.com/Trusted-AI/adversarial-robustness-toolbox)
